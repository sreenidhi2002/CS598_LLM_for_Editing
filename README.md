# CS598KD Project - Multimodal LLM for Subject-Driven Image Editing

Our project tests out subject-driven imporvments in image editing though the use of multimodal large language models (LLMs) to see if it can perform better on maintaining subject identity and spatial accuracy in the edited outputs.

### Key Challenges
- Ensuring that the embeddings generated by LLaMA-VID are compatible with the encoder in the BLIP-Diffusion model.
- Evaluating how well the model preserves subject identity and manages spatial reasoning.

## Project Setup

### Requirements

Install the required packages using pip:

```bash
pip install datasets transformers torch torchvision
```
